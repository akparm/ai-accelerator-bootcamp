# Working with Pipelines

In this module we will be working with pipelines. We will be creating a pipeline that will be used to aggregate inference results from multiple models. We will be using the Elyra tool to create the pipeline.

We will also create a pipeline to train a model. We will be using the KFP SDK to create the pipeline.

## Enable Data Science Pipelines Application

Pipelines require DSPA to be enabled, so that we can create and run pipelines from the JupyterLab workbench.

Enable DSPA by following these steps:

. In the `parasol-insurance` tenant, create a new directory named `datascience-pipelines`.

. In the `datascience-pipelines` directory, create the `base` and `overlays` directories.

. In the `base` directory, create a new file named `kustomization.yaml` and add the following content:

## Create a pipeline to aggregate inference results

Read more about the pipeline use case in the [Process claims with a pipeline](https://rh-aiservices-bu.github.io/parasol-insurance/modules/05-05-process-claims.html)

### Deploy the application via GitOps

It is required to deploy the application via GitOps before creating the pipeline. Read the instructions in the [Deploy the application via GitOps](https://rh-aiservices-bu.github.io/parasol-insurance/modules/05-03-web-app-deploy-application.html) module.

[NOTE]
====
Do not follow the application creation steps, we will use the Accelerator template to create the required application.
====

. Add a namespace for `claim-insurance-app` in the `tenants/parasol-insurance-dev/namespaces/base` directory.

. Add a directory for the `claim-insurance-app` in the `tenants/parasol-insurance-dev` directory, and include its `base/kustomize.yml` and `overlays/kustomize.yml` files.

. Add the following content to the 

### Create a pipeline to aggregate inference results

##TODO: Add the steps to create the pipeline to aggregate inference results##

## Create a pipeline to train a model

##TODO: Add the steps to create the pipeline to train a model##
